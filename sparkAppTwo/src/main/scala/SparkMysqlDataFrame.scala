/**
    Author: Fassou Mathias NIAMY
    Data Engineer @ Atos Senegal
    Date:27 June, 2020 
    Gueule Tapee, Dakar, Senegal
    This program read three data tables from MySQL and make some aggregation 
    on them and store the result back into MySQL

    **/
package net.atos.spark

import org.apache.log4j._
import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._

object SparkMysqlDataFrame {
  def main(args:Array[String]): Unit ={


    Logger.getLogger("org").setLevel(Level.ERROR)
    val spark = SparkSession.
      builder().
      master("local[*]").
      appName("").getOrCreate()
    // Read the orders table into orderDF
    val orderDF = spark.read.
      format("jdbc").
      option("url", "jdbc:mysql://localhost:3306/mydb").
      //option("driver", "com.mysql.jdbc.Driver").
      option("dbtable", "orders").
      option("user","root").
      option("password","passer").
      load()
   // orderDF.show
   // Read products table into productDF
    val productDF = spark.read.
      format("jdbc").
      option("url", "jdbc:mysql://localhost:3306/mydb").
    //  option("driver", "com.mysql.jdbc.Driver").
      option("dbtable", "products").
      option("user","root").
      option("password","passer").
      load()
   // productDF.show
   // Read orderItems table into orderItemDF
    val orderItemDF = spark.read.
      format("jdbc").
      option("url", "jdbc:mysql://localhost:3306/mydb").
      //option("driver", "com.mysql.jdbc.Driver").
      option("dbtable", "orderItems").
      option("user","root").
      option("password","passer").
      load()
    //orderItemDF.show

    import spark.implicits._

    /*Compute the revenue generated by date and products
     and sort the result in descending order.*/

    val revenueByDateAndProduct = orderDF.
      join(orderItemDF, $"orderId" === $"orderItemOrderId").
      join(productDF,$"orderItemProductId" === $"productId").
      groupBy("orderDate","productName").
      agg(round(sum("orderItemSubtotal"),2).alias("total")).sort($"total".desc)

     //revenueByDateAndProduct.show(false)
     // Write back the result into MySQL 
    revenueByDateAndProduct.write.
      mode("append").
      format("org.apache.spark.sql.jdbc")
      .options(Map(
        "url" -> "jdbc:mysql://localhost:3306/mydb?user=root&password=passer",
        "dbtable" -> "revenueByDateAndProduct"))
      .save()

  }

}
